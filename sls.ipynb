{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Straight Line Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma técnica baseada na distância entre os pontos e um segmento de reta.\n",
    "\n",
    "Seja $p, q \\in \\mathbb{R}^{d+1}$. O SLS (Straight Line Segments) $L_{p,q}$ com extremidades $p$ e $q$ é dada por: \n",
    "\n",
    "$$ L_{p,q} = \\{x \\in \\mathbb{R}^{d+1} : x = p + \\lambda (p - q), 0 \\leq \\lambda \\leq 1\\} $$ \n",
    "\n",
    "Seja $x \\in \\mathbb{R}^{d}$, definindo $x_{e} \\in \\mathbb{R}^{d+1}$ como sendo o $x$ inserido num espaço $d+1$, onde, neste eixo, possui valor zero. Vetorialmente $x_{e} = (x, 0)$\n",
    "<br>Agora definimos pseudo-distância entre $x$ e $L_{p,q}$ como:\n",
    "\n",
    "$$ distP(x,L) = \\dfrac{dist(x_{e}, p) + dist(x_{e}, q) - dist(p, q)}{2},$$\n",
    "\n",
    "onde $dist(a,b)$ é a distância euclidiana entre $a$ e $b$.\n",
    "<br>Note que se $x_{e} \\in L$, então o $distP(x,L) = 0$. E se $p = q$, $distP(x,L) = dist(x_{e},p) = dist(x_{e},q)$\n",
    "<br> Seja $\\xi$ uma coleção de SLS: \n",
    "$$\\xi = \\{L_{p_{i} ,q_{i}} : p_{i}, q_{i} \\in \\mathbb{R}^{d+1}, i = 1, ..., n\\}$$\n",
    "\n",
    "Dados duas coleções $\\xi_{0}$ e $\\xi_{1}$, vamos definir $T(x, \\xi_{0}, \\xi_{1})$ como sendo: \n",
    "$$ T(x, \\xi_{0}, \\xi_{1}) = \\sum_{L \\in \\xi_{1}} \\dfrac{1}{distP(x,L) + \\varepsilon} - \\sum_{L \\in \\xi_{0}} \\dfrac{1}{distP(x,L) + \\varepsilon} $$\n",
    "\n",
    "Observe que se $x_{e}$ está \"próximo\" de $\\xi_{0}$ e \"longe\" de $\\xi_{1}$, então $T(x, \\xi_{0}, \\xi_{1})$ tende a $-\\infty$, o caso contrário, tende a $+\\infty$.\n",
    "<br>Seja $\\xi = \\{\\xi_{0}, \\xi_{1}\\}$, a função $y_{\\xi}(x): \\mathbb{R}^{d} \\rightarrow [0,1]$ é dada por: \n",
    "$$y_{\\xi}(x) = \\dfrac{1}{1 + e^{-T(x, \\xi_{0}, \\xi_{1})}}$$\n",
    "\n",
    "Onde é também conhecido como sigmoid.\n",
    "<br>Vamos agora definir a função erro: \n",
    "$$e_{i}(y_{\\xi}) = y_{\\xi} - y_i$$\n",
    "$$E(y_{\\xi}) = \\dfrac{1}{n} \\sum_{i=1}^{n} [e_{i}(y_{\\xi})]^2 $$\n",
    "\n",
    "Assim, em geral, queremos minimizar a função $E$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placing Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Amostra $S = \\{(x_{i},y_{i}) : x_{i} \\in \\mathbb{R}^{d}, y_{i} \\in [0,1], i = 1,2,...,n\\}$\n",
    "<br>Output: Dois conjuntos $\\xi_{0}, \\xi_{1}$ de SLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placing(S):\n",
    "    x0, x1 = S[0][S[1] <= 0.5], S[0][S[1] > 0.5]\n",
    "#     d = S[0].shape[1]\n",
    "    d = 1\n",
    "    \n",
    "    x0m, x1m = np.mean(x0, axis=0), np.mean(x1, axis=0)\n",
    "    x0v, x1v = np.var(x0, axis=0), np.var(x1, axis=0)\n",
    "    x0s, x1s = x0v**0.5, x1v**0.5 #or np.std(x0, axis=0), np.std(x1, axis=0)\n",
    "    flag = True\n",
    "    while flag:\n",
    "        vec0, vec1 = np.array(rdir(d)), np.array(rdir(d))\n",
    "        if np.linalg.norm(vec0) == 1 and np.linalg.norm(vec1) == 1:\n",
    "            flag = False\n",
    "    \n",
    "    a0, a1 = x0m - np.linalg.norm(x0v)*vec0, x1m - np.linalg.norm(x1v)*vec1\n",
    "    b0, b1 = x0m + np.linalg.norm(x0v)*vec0, x1m + np.linalg.norm(x1v)*vec1\n",
    "    \n",
    "    var = np.linalg.norm(x0s) + np.linalg.norm(x1s)\n",
    "    p0, p1 = np.append(a0, var), np.append(a1, var)\n",
    "    q0, q1 = np.append(b0, var), np.append(b1, var)\n",
    "    \n",
    "    lamb = random.uniform(0,1)\n",
    "    L0 = p0 + lamb*(q0 - p0)\n",
    "    L1 = p1 + lamb*(q1 - p1)\n",
    "    return (L0, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(S, maxSLS, placing):\n",
    "    L0, L1 = placing(S)\n",
    "    countSLS = 2\n",
    "    while countSLS < maxSLS:\n",
    "        alpha = 0.1\n",
    "        error = 1\n",
    "        derror = 1\n",
    "        while derror < 1e-8 or alpha < 1e-8:\n",
    "            Disp = ComputeDisp()\n",
    "            beta = alpha\n",
    "            d = 1\n",
    "            for i in range(MAX):\n",
    "                L0, L1 = MoveSLS()\n",
    "                Olderror = error\n",
    "                derror = Olderror - error\n",
    "                error = E(yl)\n",
    "                derror = Olderror - error\n",
    "                if derror < 0:\n",
    "                    d = (-1)*d\n",
    "                beta = beta/2\n",
    "                alpha = alpha + d*beta\n",
    "        if CountSLS < maxSLS:\n",
    "            OnemoreSLS()\n",
    "        countSLS += 1\n",
    "    return (L0, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "a = 0\n",
    "while i < 10 or a < 10:\n",
    "    a+=1\n",
    "    i+=1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\xi_j = p_j + \\lambda (q_j - p_j), \\lambda \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import gauss\n",
    "#random unit vector\n",
    "def rdir(dims):\n",
    "    vec = [gauss(0, 1) for i in range(dims)]\n",
    "    mag = sum(x**2 for x in vec) ** .5\n",
    "    return [x/mag for x in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p0, q0) , (p1, q1) = placing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data\n",
    "lamb = random.uniform(0,1)\n",
    "# plt.plot(X[:, 20], y, \"x\")\n",
    "teste = (X[:,20], y)\n",
    "(p0, q0) , (p1, q1) = placing(teste)\n",
    "L0 = p0 + lamb*(q0 - p0)\n",
    "L1 = p1 + lamb*(q1 - p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
